{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.22) or chardet (2.3.0) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AffinityPropagation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from math import cos\n",
    "from math import sin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answers to holidays\n",
    "docs = [\n",
    "    'I went to France to visit Paris',\n",
    "    'New York City was crowded',\n",
    "    'sightseeing in Bali',\n",
    "    'swimming in the tropical oceans',\n",
    "    'swimming in Bali',\n",
    "    'raining in Paris',\n",
    "    'visiting monuments in Paris',\n",
    "    'San Francisco',\n",
    "    'San Francisco',\n",
    "    'flew to Berlin',\n",
    "    'enjoyed visiting eiffel tower in paris',\n",
    "    'Paris, city of love',\n",
    "    'Flying is fun',\n",
    "    'Paris is crowded',\n",
    "    'France'\n",
    "]\n",
    "\n",
    "docs = [x.strip('\\n') for x in open('real7.txt').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stripped docs [La Niaque, sales Keep investing people, focus, Align internally, Focus align accelerate, Collboration, Get back track 2015 target, Speed execution, industry moving faster, Align grow clouds, Contacts, need change, Align, can win focus, Transform, AMBITIOUS, Learning power group, Client focus, n't move fast enough, Proactive proposals, accelerate, Acceleration, Focus alignment execution, focus align accelerate, energy, innovation, technology, Mts campaign, Symphony, Focus innovate align accelerate, Energy passion alignment, Technology, Let 's get aligned, alignment acceleration, Talent, Innovation, Focus, Align, Accelerate, Big deals accounts symphony big company, Align, Innovation Now, Accelerate, Alignment key, Group 's collective capabilities partnership power, Flywheel, Social, Focus align accelerate, Innovation, New offerings, Growth, Innovation new world, Bring entire portfolio units clients sell deliver seamlessly, Netsuite, Focus different, Focus joint teaming, Focus Align Accelerate, inspiration accelerate, Innovation speed teamwork passion, Industrialised & Symphony, Alignement acceleration, Alignment, Align focus accelerate, Alignment alignment, Accelerate, Align, 're behind, Reuse flywheel collaboration, power group, Sales sales, excellent relationships partners family, Simplicity, Need investment, Innovation, stronger work together, Showcases, Acceleration, Focus, Align, Align, Pride, Illuminating inspiring, 19% GOP, Deliver 2013 Alliances, Service Software Product, Inspiring, Growth, Innovation, Accelerate cooperate need row together, urgency speed, Customer focus alignment, Accelerate, Growth agenda, Customer centricity, cloud cloud cloud orchestration determing future, Fly wheel]\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words\n",
    "\n",
    "def stop_word_stripper(line):\n",
    "    stop_words = [w.strip('\\n').lower() for w in open('stop_words.txt').readlines()]\n",
    "    pos_stopper = ['PUNCT', 'SYM']\n",
    "    return ' '.join([token.text for token in line if str(token).lower() not in stop_words and token.pos_  not in pos_stopper])\n",
    "\n",
    "stripped_docs = [] #spacy object\n",
    "copy_docs = [] # strings\n",
    "for d in docs:\n",
    "    stripped_docs.append(nlp(stop_word_stripper(nlp(d))))\n",
    "    copy_docs.append(stop_word_stripper(nlp(d)))\n",
    "    \n",
    "print('stripped docs', stripped_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'La Niaque': 1, '2015': 1, 'Acceleration': 2, 'Group': 1, 'Focus Align Accelerate': 1, 'Industrialised & Symphony': 1, 'Pride': 1, '19% GOP': 1, 'Service Software Product': 1} ['', 'sales Keep investing people', 'focus', 'Align internally', 'Focus align accelerate', 'Collboration', 'Get back track  target', 'Speed execution', 'industry moving faster', 'Align grow clouds', 'Contacts', 'need change', 'Align', 'can win focus', 'Transform', 'AMBITIOUS', 'Learning power group', 'Client focus', \"n't move fast enough\", 'Proactive proposals', 'accelerate', '', 'Focus alignment execution', 'focus align accelerate', 'energy', 'innovation', 'technology', 'Mts campaign', 'Symphony', 'Focus innovate align accelerate', 'Energy passion alignment', 'Technology', \"Let 's get aligned\", 'alignment acceleration', 'Talent', 'Innovation', 'Focus', 'Align', 'Accelerate', 'Big deals accounts symphony big company', 'Align', 'Innovation Now', 'Accelerate', 'Alignment key', \"'s collective capabilities partnership power\", 'Flywheel', 'Social', 'Focus align accelerate', 'Innovation', 'New offerings', 'Growth', 'Innovation new world', 'Bring entire portfolio units clients sell deliver seamlessly', 'Netsuite', 'Focus different', 'Focus joint teaming', '', 'inspiration accelerate', 'Innovation speed teamwork passion', '', 'Alignement acceleration', 'Alignment', 'Align focus accelerate', 'Alignment alignment', 'Accelerate', 'Align', \"'re behind\", 'Reuse flywheel collaboration', 'power group', 'Sales sales', 'excellent relationships partners family', 'Simplicity', 'Need investment', 'Innovation', 'stronger work together', 'Showcases', '', 'Focus', 'Align', 'Align', '', 'Illuminating inspiring', '', 'Deliver 2013 Alliances', '', 'Inspiring', 'Growth', 'Innovation', 'Accelerate cooperate need row together', 'urgency speed', 'Customer focus alignment', 'Accelerate', 'Growth agenda', 'Customer centricity', 'cloud cloud cloud orchestration determing future', 'Fly wheel']\n"
     ]
    }
   ],
   "source": [
    "# parse through to get entities \n",
    "kw_freq = {}\n",
    "\n",
    "for i in range(len(stripped_docs)):\n",
    "    line = stripped_docs[i]\n",
    "    for e in line.ents:\n",
    "        copy_docs[i] = copy_docs[i].replace(e.text, '').strip()\n",
    "        if e.text in kw_freq:\n",
    "            kw_freq[e.text] += 1\n",
    "        else:\n",
    "            kw_freq[e.text] = 1\n",
    "\n",
    "print(kw_freq, copy_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'La Niaque': 1, '2015': 1, 'Acceleration': 2, 'Group': 1, 'Focus Align Accelerate': 1, 'Industrialised & Symphony': 1, 'Pride': 1, '19% GOP': 1, 'Service Software Product': 1, 'sale': 2, 'keep': 1, 'invest': 1, 'people': 1, 'focu': 3, 'align': 14, 'internally': 1, 'focus': 11, 'accelerate': 12, 'collboration': 1, 'get': 2, 'back': 1, 'track': 1, 'target': 1, 'speed': 3, 'execution': 2, 'industry': 1, 'move': 2, 'faster': 1, 'grow': 1, 'cloud': 4, 'contact': 1, 'change': 1, 'can': 1, 'win': 1, 'transform': 1, 'ambitious': 1, 'learning': 1, 'power': 3, 'group': 2, 'client': 2, \"n't\": 1, 'fast': 1, 'enough': 1, 'proactive': 1, 'proposal': 1, 'alignment': 8, 'energy': 2, 'innovation': 8, 'technology': 2, 'mts': 1, 'campaign': 1, 'symphony': 2, 'innovate': 1, 'passion': 2, 'let': 1, 'acceleration': 2, 'talent': 1, 'big': 2, 'deal': 1, 'account': 1, 'company': 1, 'now': 1, 'key': 1, 'collective': 1, 'capability': 1, 'partnership': 1, 'flywheel': 2, 'social': 1, 'new': 2, 'offering': 1, 'growth': 3, 'world': 1, 'bring': 1, 'entire': 1, 'portfolio': 1, 'unit': 1, 'sell': 1, 'deliver': 2, 'seamlessly': 1, 'netsuite': 1, 'different': 1, 'joint': 1, 'team': 1, 'inspiration': 1, 'teamwork': 1, 'alignement': 1, 'behind': 1, 'reuse': 1, 'collaboration': 1, 'sal': 1, 'excellent': 1, 'relationship': 1, 'partner': 1, 'family': 1, 'simplicity': 1, 'need': 2, 'investment': 1, 'strong': 1, 'work': 1, 'together': 2, 'showcas': 1, 'illuminating': 1, 'inspire': 1, '2013': 1, 'alliances': 1, 'inspiring': 1, 'cooperate': 1, 'row': 1, 'urgency': 1, 'customer': 2, 'agenda': 1, 'centricity': 1, 'orchestration': 1, 'determ': 1, 'future': 1, 'fly': 1, 'wheel': 1}\n"
     ]
    }
   ],
   "source": [
    "# get lemma keywords \n",
    "# join the rest of the words together: \n",
    "from hunspell import Hunspell\n",
    "h = Hunspell();\n",
    "\n",
    "corpus = nlp(' '.join(copy_docs))\n",
    "\n",
    "MIN_CHARACTERS = 3\n",
    "\n",
    "for token in corpus:\n",
    "    if len(token.lemma_) >= MIN_CHARACTERS:\n",
    "        word = token.lemma_\n",
    "        if word.lower == word:\n",
    "            if not h.spell(token.lemma_):\n",
    "                if len(h.suggest(token.lemma_)) > 0:\n",
    "                    word = h.suggest(token.lemma_)[0]\n",
    "        if word in kw_freq:\n",
    "            kw_freq[word] += 1\n",
    "        else:\n",
    "            kw_freq[word] = 1\n",
    "\n",
    "print(kw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'La Niaque': 1, '2015': 1, 'Acceleration': 4, 'Focus Align Accelerate': 1, 'Industrialised & Symphony': 1, 'Pride': 1, '19% GOP': 1, 'Service Software Product': 1, 'sale': 2, 'keep': 1, 'invest': 1, 'people': 1, 'focu': 3, 'align': 14, 'internally': 1, 'focus': 11, 'accelerate': 12, 'collboration': 1, 'get': 2, 'back': 1, 'track': 1, 'target': 1, 'speed': 3, 'execution': 2, 'industry': 1, 'move': 2, 'faster': 1, 'grow': 1, 'cloud': 4, 'contact': 1, 'change': 1, 'can': 1, 'win': 1, 'transform': 1, 'ambitious': 1, 'learning': 1, 'power': 3, 'group': 3, 'client': 2, \"n't\": 1, 'fast': 1, 'enough': 1, 'proactive': 1, 'proposal': 1, 'alignment': 8, 'energy': 2, 'innovation': 8, 'technology': 2, 'mts': 1, 'campaign': 1, 'symphony': 2, 'innovate': 1, 'passion': 2, 'let': 1, 'acceleration': 4, 'talent': 1, 'big': 2, 'deal': 1, 'account': 1, 'company': 1, 'now': 1, 'key': 1, 'collective': 1, 'capability': 1, 'partnership': 1, 'flywheel': 2, 'social': 1, 'new': 2, 'offering': 1, 'growth': 3, 'world': 1, 'bring': 1, 'entire': 1, 'portfolio': 1, 'unit': 1, 'sell': 1, 'deliver': 2, 'seamlessly': 1, 'netsuite': 1, 'different': 1, 'joint': 1, 'team': 1, 'inspiration': 1, 'teamwork': 1, 'alignement': 1, 'behind': 1, 'reuse': 1, 'collaboration': 1, 'sal': 1, 'excellent': 1, 'relationship': 1, 'partner': 1, 'family': 1, 'simplicity': 1, 'need': 2, 'investment': 1, 'strong': 1, 'work': 1, 'together': 2, 'showcas': 1, 'illuminating': 1, 'inspire': 1, '2013': 1, 'alliances': 1, 'inspiring': 1, 'cooperate': 1, 'row': 1, 'urgency': 1, 'customer': 2, 'agenda': 1, 'centricity': 1, 'orchestration': 1, 'determ': 1, 'future': 1, 'fly': 1, 'wheel': 1}\n"
     ]
    }
   ],
   "source": [
    "# proper casing\n",
    "\n",
    "caseless_freq = {}\n",
    "propercase_freq = {}\n",
    "\n",
    "for kw, count in kw_freq.items():\n",
    "    if kw in caseless_freq:\n",
    "        caseless_freq[kw.lower()].append(count)\n",
    "    else:\n",
    "        caseless_freq[kw.lower()] = [count]\n",
    "\n",
    "for kw, count in kw_freq.items():\n",
    "    if count == max(caseless_freq[kw.lower()]):\n",
    "        propercase_freq[kw] = sum(caseless_freq[kw.lower()])\n",
    "\n",
    "print(propercase_freq)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116, 300) ['La Niaque', '2015', 'Acceleration', 'Focus Align Accelerate', 'Industrialised & Symphony', 'Pride', '19% GOP', 'Service Software Product', 'sale', 'keep', 'invest', 'people', 'focu', 'align', 'internally', 'focus', 'accelerate', 'collboration', 'get', 'back', 'track', 'target', 'speed', 'execution', 'industry', 'move', 'faster', 'grow', 'cloud', 'contact', 'change', 'can', 'win', 'transform', 'ambitious', 'learning', 'power', 'group', 'client', \"n't\", 'fast', 'enough', 'proactive', 'proposal', 'alignment', 'energy', 'innovation', 'technology', 'mts', 'campaign', 'symphony', 'innovate', 'passion', 'let', 'acceleration', 'talent', 'big', 'deal', 'account', 'company', 'now', 'key', 'collective', 'capability', 'partnership', 'flywheel', 'social', 'new', 'offering', 'growth', 'world', 'bring', 'entire', 'portfolio', 'unit', 'sell', 'deliver', 'seamlessly', 'netsuite', 'different', 'joint', 'team', 'inspiration', 'teamwork', 'alignement', 'behind', 'reuse', 'collaboration', 'sal', 'excellent', 'relationship', 'partner', 'family', 'simplicity', 'need', 'investment', 'strong', 'work', 'together', 'showcas', 'illuminating', 'inspire', '2013', 'alliances', 'inspiring', 'cooperate', 'row', 'urgency', 'customer', 'agenda', 'centricity', 'orchestration', 'determ', 'future', 'fly', 'wheel']\n"
     ]
    }
   ],
   "source": [
    "glove_vectors = []\n",
    "labels_array = []\n",
    "\n",
    "for kw, count in propercase_freq.items():\n",
    "    labels_array.append(kw)\n",
    "    if nlp(kw)[0].vector.any() :\n",
    "        glove_vectors.append(nlp(kw)[0].vector)\n",
    "    else:\n",
    "        glove_vectors.append(np.array([0]*300))\n",
    "print(np.array(glove_vectors).shape, labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'La Niaque': 0, '2015': 2, 'Acceleration': 6, 'Focus Align Accelerate': 1, 'Industrialised & Symphony': 2, 'Pride': 8, '19% GOP': 2, 'Service Software Product': 11, 'sale': 2, 'keep': 8, 'invest': 10, 'people': 3, 'focu': 2, 'align': 2, 'internally': 2, 'focus': 1, 'accelerate': 4, 'collboration': 2, 'get': 3, 'back': 3, 'track': 2, 'target': 1, 'speed': 4, 'execution': 2, 'industry': 5, 'move': 8, 'faster': 4, 'grow': 8, 'cloud': 2, 'contact': 2, 'change': 8, 'can': 3, 'win': 3, 'transform': 8, 'ambitious': 2, 'learning': 1, 'power': 8, 'group': 2, 'client': 11, \"n't\": 3, 'fast': 4, 'enough': 3, 'proactive': 1, 'proposal': 2, 'alignment': 1, 'energy': 1, 'innovation': 5, 'technology': 5, 'mts': 2, 'campaign': 8, 'symphony': 2, 'innovate': 5, 'passion': 8, 'let': 8, 'acceleration': 6, 'talent': 8, 'big': 3, 'deal': 3, 'account': 2, 'company': 11, 'now': 3, 'key': 1, 'collective': 8, 'capability': 1, 'partnership': 7, 'flywheel': 2, 'social': 1, 'new': 8, 'offering': 8, 'growth': 10, 'world': 8, 'bring': 8, 'entire': 8, 'portfolio': 10, 'unit': 2, 'sell': 3, 'deliver': 8, 'seamlessly': 2, 'netsuite': 9, 'different': 3, 'joint': 7, 'team': 8, 'inspiration': 8, 'teamwork': 5, 'alignement': 2, 'behind': 8, 'reuse': 2, 'collaboration': 7, 'sal': 2, 'excellent': 2, 'relationship': 1, 'partner': 7, 'family': 8, 'simplicity': 2, 'need': 3, 'investment': 10, 'strong': 8, 'work': 8, 'together': 8, 'showcas': 2, 'illuminating': 2, 'inspire': 8, '2013': 2, 'alliances': 7, 'inspiring': 8, 'cooperate': 2, 'row': 2, 'urgency': 2, 'customer': 11, 'agenda': 1, 'centricity': 2, 'orchestration': 2, 'determ': 2, 'future': 8, 'fly': 3, 'wheel': 2}\n"
     ]
    }
   ],
   "source": [
    "# AffinityPropagation clustering \n",
    "\n",
    "AffinityPropagation_model = AffinityPropagation()\n",
    "AffinityPropagation_model.fit(glove_vectors)\n",
    "\n",
    "cluster_labels    = AffinityPropagation_model.labels_\n",
    "\n",
    "clusters = {}\n",
    "kw_cluster = {}\n",
    "for i in range(len(labels_array)):\n",
    "    if cluster_labels[i] not in clusters:\n",
    "        clusters[cluster_labels[i]] = [labels_array[i]]\n",
    "    else:\n",
    "        clusters[cluster_labels[i]].append(labels_array[i])\n",
    "    kw_cluster[labels_array[i]] = cluster_labels[i]\n",
    "\n",
    "print (kw_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# k means clustering \\n\\nkmeans_model = KMeans(init='k-means++', n_clusters=4, n_init=5)\\nkmeans_model.fit(glove_vectors)\\n\\n\\ncluster_labels    = kmeans_model.labels_\\n\\nclusters = {}\\nkw_cluster = {}\\nfor i in range(len(labels_array)):\\n    if cluster_labels[i] not in clusters:\\n        clusters[cluster_labels[i]] = [labels_array[i]]\\n    else:\\n        clusters[cluster_labels[i]].append(labels_array[i])\\n    kw_cluster[labels_array[i]] = cluster_labels[i]\\n\\nprint (kw_cluster)\\n\""
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# k means clustering \n",
    "\n",
    "kmeans_model = KMeans(init='k-means++', n_clusters=4, n_init=5)\n",
    "kmeans_model.fit(glove_vectors)\n",
    "\n",
    "\n",
    "cluster_labels    = kmeans_model.labels_\n",
    "\n",
    "clusters = {}\n",
    "kw_cluster = {}\n",
    "for i in range(len(labels_array)):\n",
    "    if cluster_labels[i] not in clusters:\n",
    "        clusters[cluster_labels[i]] = [labels_array[i]]\n",
    "    else:\n",
    "        clusters[cluster_labels[i]].append(labels_array[i])\n",
    "    kw_cluster[labels_array[i]] = cluster_labels[i]\n",
    "\n",
    "print (kw_cluster)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py:644: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "#distance matrix (len(cluster_labels)^2)\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "n = len(labels_array)\n",
    "\n",
    "distance_matrix = np.zeros([n, n])\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        distance_matrix[i][j] = spatial.distance.cosine(glove_vectors[i], glove_vectors[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'align': 80, 'accelerate': 72, 'focus': 68, 'alignment': 56, 'innovation': 56, 'Acceleration': 41, 'cloud': 41, 'acceleration': 41, 'focu': 37, 'speed': 37, 'power': 37, 'group': 37, 'growth': 37, 'sale': 33, 'get': 33, 'execution': 33, 'move': 33, 'client': 33, 'energy': 33, 'technology': 33, 'symphony': 33, 'passion': 33, 'big': 33, 'flywheel': 33, 'new': 33, 'deliver': 33, 'need': 33, 'together': 33, 'customer': 33, 'La Niaque': 30, '2015': 30, 'Focus Align Accelerate': 30, 'Industrialised & Symphony': 30, 'Pride': 30, '19% GOP': 30, 'Service Software Product': 30, 'keep': 30, 'invest': 30, 'people': 30, 'internally': 30, 'collboration': 30, 'back': 30, 'track': 30, 'target': 30, 'industry': 30, 'faster': 30, 'grow': 30, 'contact': 30, 'change': 30, 'can': 30, 'win': 30, 'transform': 30, 'ambitious': 30, 'learning': 30, \"n't\": 30, 'fast': 30, 'enough': 30, 'proactive': 30, 'proposal': 30, 'mts': 30, 'campaign': 30, 'innovate': 30, 'let': 30, 'talent': 30, 'deal': 30, 'account': 30, 'company': 30, 'now': 30, 'key': 30, 'collective': 30, 'capability': 30, 'partnership': 30, 'social': 30, 'offering': 30, 'world': 30, 'bring': 30, 'entire': 30, 'portfolio': 30, 'unit': 30, 'sell': 30, 'seamlessly': 30, 'netsuite': 30, 'different': 30, 'joint': 30, 'team': 30, 'inspiration': 30, 'teamwork': 30, 'alignement': 30, 'behind': 30, 'reuse': 30, 'collaboration': 30, 'sal': 30, 'excellent': 30, 'relationship': 30, 'partner': 30, 'family': 30, 'simplicity': 30, 'investment': 30, 'strong': 30, 'work': 30, 'showcas': 30, 'illuminating': 30, 'inspire': 30, '2013': 30, 'alliances': 30, 'inspiring': 30, 'cooperate': 30, 'row': 30, 'urgency': 30, 'agenda': 30, 'centricity': 30, 'orchestration': 30, 'determ': 30, 'future': 30, 'fly': 30, 'wheel': 30}\n"
     ]
    }
   ],
   "source": [
    "# assign max font size\n",
    "\n",
    "def assign_font_size(propercase_freq, max_size, min_size):\n",
    "    label_fs = {}\n",
    "    sorted_tuples = [(k, propercase_freq[k]) for k in sorted(propercase_freq, key=propercase_freq.get, reverse=True)]\n",
    "    min_count = sorted_tuples[-1][1]\n",
    "    max_count = sorted_tuples[0][1]\n",
    "    \n",
    "    for kw, count in sorted_tuples:\n",
    "        if (max_count - min_count) == 0:\n",
    "            size = int((max_size - min_size) / 2.0 + min_size)\n",
    "        else:\n",
    "            #size = int(min_size + (max_size - min_size) * (count * 1.0 / (max_count - min_count)) ** 0.8)\n",
    "            size = int((max_size - min_size)/(max_count - min_count)*count + min_size - (max_size - min_size)/(max_count - min_count)*min_count)\n",
    "        label_fs[kw] = size\n",
    "    \n",
    "    return (label_fs)\n",
    "        \n",
    "kw_fs = assign_font_size(propercase_freq, 80, 30) #keyword_font_size\n",
    "print(kw_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'align': (260, 80), 'accelerate': (468, 72), 'focus': (221, 68), 'alignment': (327, 56), 'innovation': (364, 56), 'Acceleration': (319, 41), 'cloud': (133, 41), 'acceleration': (319, 41), 'focu': (96, 37), 'speed': (120, 37), 'power': (120, 37), 'group': (120, 37), 'growth': (144, 37), 'sale': (85, 33), 'get': (64, 33), 'execution': (193, 33), 'move': (85, 33), 'client': (128, 33), 'energy': (128, 33), 'technology': (214, 33), 'symphony': (171, 33), 'passion': (150, 33), 'big': (64, 33), 'flywheel': (171, 33), 'new': (64, 33), 'deliver': (150, 33), 'need': (85, 33), 'together': (171, 33), 'customer': (171, 33), 'La Niaque': (175, 30), '2015': (78, 30), 'Focus Align Accelerate': (429, 30), 'Industrialised & Symphony': (487, 30), 'Pride': (97, 30), '19% GOP': (136, 30), 'Service Software Product': (468, 30), 'keep': (78, 30), 'invest': (117, 30), 'people': (117, 30), 'internally': (195, 30), 'collboration': (234, 30), 'back': (78, 30), 'track': (97, 30), 'target': (117, 30), 'industry': (156, 30), 'faster': (117, 30), 'grow': (78, 30), 'contact': (136, 30), 'change': (117, 30), 'can': (58, 30), 'win': (58, 30), 'transform': (175, 30), 'ambitious': (175, 30), 'learning': (156, 30), \"n't\": (58, 30), 'fast': (78, 30), 'enough': (117, 30), 'proactive': (175, 30), 'proposal': (156, 30), 'mts': (58, 30), 'campaign': (156, 30), 'innovate': (156, 30), 'let': (58, 30), 'talent': (117, 30), 'deal': (78, 30), 'account': (136, 30), 'company': (136, 30), 'now': (58, 30), 'key': (58, 30), 'collective': (195, 30), 'capability': (195, 30), 'partnership': (214, 30), 'social': (117, 30), 'offering': (156, 30), 'world': (97, 30), 'bring': (97, 30), 'entire': (117, 30), 'portfolio': (175, 30), 'unit': (78, 30), 'sell': (78, 30), 'seamlessly': (195, 30), 'netsuite': (156, 30), 'different': (175, 30), 'joint': (97, 30), 'team': (78, 30), 'inspiration': (214, 30), 'teamwork': (156, 30), 'alignement': (195, 30), 'behind': (117, 30), 'reuse': (97, 30), 'collaboration': (253, 30), 'sal': (58, 30), 'excellent': (175, 30), 'relationship': (234, 30), 'partner': (136, 30), 'family': (117, 30), 'simplicity': (195, 30), 'investment': (195, 30), 'strong': (117, 30), 'work': (78, 30), 'showcas': (136, 30), 'illuminating': (234, 30), 'inspire': (136, 30), '2013': (78, 30), 'alliances': (175, 30), 'inspiring': (175, 30), 'cooperate': (175, 30), 'row': (58, 30), 'urgency': (136, 30), 'agenda': (117, 30), 'centricity': (195, 30), 'orchestration': (253, 30), 'determ': (117, 30), 'future': (117, 30), 'fly': (58, 30), 'wheel': (97, 30)}\n"
     ]
    }
   ],
   "source": [
    "def max_dimensions(kw_fs):\n",
    "    kw_dimensions = {}\n",
    "    for kw, fs in kw_fs.items():\n",
    "        kw_dimensions[kw] = (int(0.65*len(kw)*fs), fs) #x, y (i.e. width, height)\n",
    "    return kw_dimensions\n",
    "\n",
    "kw_max_dim = max_dimensions(kw_fs)\n",
    "print(kw_max_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word:\n",
    "    def __init__(self, word, size, font_size, cluster):\n",
    "        self.word = word\n",
    "        self.width = size[\"width\"] #{width, height}\n",
    "        self.height = size[\"height\"]\n",
    "        self.font_size = font_size\n",
    "        self.cluster = cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cloud:\n",
    "    def __init__(self, words=[], canvas_size={\"x\": 1920, \"y\": 1080}, filename='clouds.html'):\n",
    "        self.words = words\n",
    "        self.canvas = [] #{word, font_size, x, y, width, height, color, cluster} <== color to be added\n",
    "        self.canvas_size = canvas_size\n",
    "        self.clusters = self.generate_clusters() # {0 : cluster0, 1 : cluster1, ...etc}\n",
    "        self.filename = filename\n",
    "        self.colors = [\"#6F694E\", \"#65D0B2\", \"#D8F546\", \"#FF724B\", \"#D6523E\", \"#B3F0E6\", \"#EAF380\", \"#A7328E\", \"#33DB45\", \"#EAEA45\", \"#63FFF3\", \"#7488AC\", \"#C0F8E1\"]\n",
    "        self.positions = []\n",
    "        \n",
    "    def generate_clusters(self):\n",
    "        clusters = {}\n",
    "        for w in self.words:\n",
    "            if w.cluster in clusters:\n",
    "                clusters[w.cluster].append(w)\n",
    "            else:\n",
    "                clusters[w.cluster] = [w]\n",
    "        return clusters\n",
    "    \n",
    "    '''\n",
    "    def choose_cluster_start(self):\n",
    "        start_points = {}\n",
    "        start_point = {}\n",
    "        r = 0\n",
    "        for i in range(len(self.clusters)):\n",
    "            c = self.clusters[i]\n",
    "            n = len(c)\n",
    "            \n",
    "            H = self.canvas_size[\"y\"] #total height\n",
    "            L = self.canvas_size[\"x\"] #total length\n",
    "            \n",
    "            if i%2 == 0:\n",
    "                y = random.randint(int(0.1*H), int(0.55*H))\n",
    "            else:\n",
    "                y = random.randint(int(0.55*H), int(0.9*H))\n",
    "            x = random.randint(int(r*L), min(int((r+len(c)/len(self.words))*L), int(L*0.90)))\n",
    "            \n",
    "            r = min(0.85, r + len(c)/len(self.words))\n",
    "            start_points[c[0].cluster] = {\n",
    "                \"x\": x,\n",
    "                \"y\": y\n",
    "            }\n",
    "        return start_points\n",
    "    '''\n",
    "        \n",
    "    def create_cloud(self):\n",
    "        \n",
    "        # sort by cluster size\n",
    "        # sort by max font-size\n",
    "        cl_size = {}\n",
    "        for c, words in self.clusters.items():\n",
    "            if len(words) < 4:\n",
    "                avg_size = sum([w.font_size for w in words])//len(words)\n",
    "            else:\n",
    "                avg_size = sum(sorted([w.font_size for w in words])[::-1][:4])/4\n",
    "            cl_size[c] = avg_size*3 - len(words)\n",
    "        sorted_clusters = sorted(cl_size, key=cl_size.get)[::-1]\n",
    "        \n",
    "        start_position = { \"x\": 1920//2, \"y\": 1080//2 }\n",
    "        \n",
    "        for i in range(len(sorted_clusters)):\n",
    "            c = sorted_clusters[i]\n",
    "            words = self.clusters[c]\n",
    "            self.positions = self.spiral(start_position)\n",
    "            \n",
    "            for w in words:\n",
    "                new_position = self.add_word_to_cloud(w) \n",
    "            \n",
    "            max_left_cloud = min([c[\"x\"] for c in self.canvas])\n",
    "            max_right_cloud = max([c[\"x\"] for c in self.canvas])\n",
    "            shift = 30\n",
    "            if i%2 == 0:\n",
    "                if new_position[\"x\"] < 1920//2: \n",
    "                    start_position = { \"x\" : min(1920//2 + new_position[\"x\"], max_right_cloud + shift), \"y\": new_position[\"y\"] }\n",
    "                if new_position[\"x\"] > 1920//2: \n",
    "                    start_position = { \"x\" : max(1920 - new_position[\"x\"], max_left_cloud - shift), \"y\": new_position[\"y\"] }\n",
    "            else:\n",
    "                start_position = new_position\n",
    "        \n",
    "        self.center_cloud()\n",
    "        \n",
    "    def draw_cloud_to_svg(self):\n",
    "        f = open(self.filename, 'w')\n",
    "        f.write('<svg viewbox=\"0 0 1920 1080\" style=\"background: black\">')\n",
    "        for w in self.canvas:\n",
    "           \n",
    "\n",
    "            #f.write(' <rect x=\"{}\" y=\"{}\" width=\"{}\" height=\"{}\"/>'.format( w[\"x\"], w[\"y\"], w[\"width\"], w[\"height\"]))\n",
    "            f.write('<text x=\"{}\" y=\"{}\" font-family=\"Verdana\" font-size=\"{}\" fill=\"{}\">'.format(w[\"x\"], w[\"y\"], w[\"font_size\"], w[\"color\"]))\n",
    "            f.write(w[\"word\"])\n",
    "            f.write('</text>\\n')\n",
    "        f.write('</svg>')\n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "    def add_word_to_cloud(self, word): # word class Word        \n",
    "        print(len(self.positions))\n",
    "        for p in self.positions:\n",
    "            if not self.verify_overlap( word, p):\n",
    "                self.canvas.append({\n",
    "                    \"word\": word.word,\n",
    "                    \"x\": p[\"x\"],\n",
    "                    \"y\": p[\"y\"],\n",
    "                    \"width\": word.width,\n",
    "                    \"height\": word.height,\n",
    "                    \"font_size\": word.font_size,\n",
    "                    \"color\": self.colors[word.cluster],\n",
    "                    \"cluster\": word.cluster\n",
    "                })\n",
    "                self.positions.remove(p)\n",
    "                return p\n",
    "        return self.positions[-1]\n",
    "            \n",
    "\n",
    "    def rect_intersection(self, r1, r2):\n",
    "        p1 = {}\n",
    "        p1[\"x\"] = r1[\"x\"]\n",
    "        p1[\"y\"] = r1[\"y\"] - r1[\"height\"]\n",
    "\n",
    "        p2 = {}\n",
    "        p2[\"x\"] = r1[\"x\"] + r1[\"width\"]\n",
    "        p2[\"y\"] = r1[\"y\"]\n",
    "\n",
    "        p3 = {}\n",
    "        p3[\"x\"] = r2[\"x\"]\n",
    "        p3[\"y\"] = r2[\"y\"] - r2[\"height\"]\n",
    "\n",
    "        p4 = {}\n",
    "        p4[\"x\"] = r2[\"x\"] + r2[\"width\"]\n",
    "        p4[\"y\"] = r2[\"y\"]\n",
    "\n",
    "        return not(p2[\"y\"] < p3[\"y\"] or p1[\"y\"] > p4[\"y\"] or p2[\"x\"] < p3[\"x\"] or p1[\"x\"] > p4[\"x\"])\n",
    "\n",
    "    \n",
    "    def verify_overlap(self, word, position): # true if overlaps, false if not\n",
    "        new_rect = {\n",
    "            \"x\": position[\"x\"],\n",
    "            \"y\": position[\"y\"],\n",
    "            \"width\": word.width,\n",
    "            \"height\": word.height\n",
    "        }\n",
    "        for filled_rect in self.canvas:\n",
    "            if self.rect_intersection(filled_rect, new_rect):\n",
    "                return True\n",
    "        #verify out of bound of rectangle:\n",
    "        if new_rect[\"x\"] < 0 or new_rect[\"x\"] + new_rect[\"width\"] > 1920 or new_rect[\"y\"] > 1080 or new_rect[\"y\"]- new_rect[\"height\"] < 0:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "\n",
    "    def spiral(self, start_point): # returns an [] with positions to test \n",
    "        points = [start_point]\n",
    "        # x = (a + b*theta)cos(theta)\n",
    "        # y = (a + b*theta)sin(theta)\n",
    "\n",
    "        # b = a final - a ini / 2 pi n  n=number of turns\n",
    "        a_ini = 0\n",
    "        # a_final = self.canvas_size[\"x\"]*len(self.clusters[cluster])/len(self.words) #spiral radius \n",
    "        a_final = self.canvas_size[\"x\"] #spiral radius \n",
    "\n",
    "        b = (a_final - a_ini)/(2*3.14159*(self.canvas_size[\"x\"]/10))\n",
    "\n",
    "        thetas = [ (self.canvas_size[\"y\"]/10 * 2)/1000 *x for x in range(1000)]\n",
    "        for i in thetas: #1000 points\n",
    "            x = ( a_ini + b*i + cos(i)*b/10)*cos(i) + start_point[\"x\"]\n",
    "            y = ( a_ini + b*i + cos(i)*b/10)*sin(i) + start_point[\"y\"]\n",
    "            points.append({\"x\": x, \"y\": y})\n",
    "\n",
    "        return points\n",
    "    \n",
    "    def center_cloud(self):\n",
    "        xs = [c[\"x\"] for c in self.canvas]\n",
    "        ys = [c[\"y\"] for c in self.canvas]\n",
    "        \n",
    "        x_min = min(xs)\n",
    "        x_max = max(xs)\n",
    "        \n",
    "        y_min = min(ys)\n",
    "        y_max = max(ys)\n",
    "        \n",
    "        shift_x = x_min - (1920 - (x_max - x_min))//2\n",
    "        shift_y = y_min - (1080 - (y_max - y_min))//2\n",
    "        \n",
    "        for c in self.canvas:\n",
    "            c[\"x\"] -= shift_x\n",
    "            c[\"y\"] -= shift_y\n",
    "        \n",
    "        \n",
    "    '''\n",
    "    def compress(self):\n",
    "        # pull words towards the one zith the most occurence\n",
    "        # create line \n",
    "        # test positions along that line \n",
    "        sizes = []\n",
    "        for w in self.canvas:\n",
    "            sizes.append(w[\"font_size\"])\n",
    "        central_word = self.canvas[sizes.index(max(sizes))]\n",
    "        \n",
    "        for w in self.canvas:\n",
    "            if w[\"cluster\"] != central_word[\"cluster\"]:\n",
    "                # sort tham by distance \n",
    "                pos_central_word = np.array([central_word[\"x\"], central_word[\"y\"]])\n",
    "                pos_w = np.array([w[\"x\"], w[\"y\"]])\n",
    "                dist = numpy.sqrt(numpy.sum((pos_central_word - pos_w)**2))\n",
    "                \n",
    "                # draw line \n",
    "                # inch closer \n",
    "                coeff = central_word[\"y\"] - w[\"y\"] / central_word[\"x\"] - w[\"x\"]\n",
    "                coordiantes = [{\"x\": central_word[\"x\"] + (central_word[\"x\"] - w[\"x\"])/100 * i, \"y\": central_word[\"y\"] + coeff* (central_word[\"x\"] - w[\"x\"])/100 * i } for i in range(100)]\n",
    "                for c in coordinates:\n",
    "                    for word in self.words:\n",
    "                        if self.verify_overlap(word, c):\n",
    "                            break\n",
    "    '''             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n",
      "1000\n",
      "999\n",
      "998\n",
      "997\n",
      "996\n",
      "995\n",
      "994\n",
      "993\n",
      "992\n",
      "991\n",
      "990\n",
      "1001\n",
      "1000\n",
      "999\n",
      "998\n",
      "1001\n",
      "1000\n",
      "1001\n",
      "1000\n",
      "999\n",
      "998\n",
      "997\n",
      "996\n",
      "995\n",
      "994\n",
      "993\n",
      "992\n",
      "991\n",
      "990\n",
      "989\n",
      "988\n",
      "987\n",
      "986\n",
      "985\n",
      "984\n",
      "983\n",
      "982\n",
      "981\n",
      "980\n",
      "979\n",
      "978\n",
      "977\n",
      "976\n",
      "975\n",
      "974\n",
      "973\n",
      "972\n",
      "971\n",
      "970\n",
      "969\n",
      "968\n",
      "967\n",
      "966\n",
      "1001\n",
      "1000\n",
      "999\n",
      "998\n",
      "997\n",
      "1001\n",
      "1000\n",
      "999\n",
      "998\n",
      "1001\n",
      "1000\n",
      "999\n",
      "998\n",
      "1001\n",
      "1001\n",
      "1001\n",
      "1000\n",
      "999\n",
      "998\n",
      "997\n",
      "1001\n",
      "1000\n",
      "999\n",
      "998\n",
      "997\n",
      "996\n",
      "995\n",
      "994\n",
      "993\n",
      "992\n",
      "991\n",
      "990\n",
      "989\n",
      "988\n",
      "1001\n",
      "1000\n",
      "999\n",
      "998\n",
      "997\n",
      "996\n",
      "995\n",
      "994\n",
      "993\n",
      "992\n",
      "991\n",
      "990\n",
      "989\n",
      "988\n",
      "987\n",
      "986\n",
      "985\n",
      "984\n",
      "983\n",
      "982\n",
      "981\n",
      "980\n",
      "979\n",
      "978\n",
      "977\n",
      "976\n",
      "975\n",
      "974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nimport matplotlib.pyplot as plt\\n\\nfig = plt.figure(figsize=(10,10))\\n\\nax = fig.add_subplot(111)\\nfig.subplots_adjust(top=0.85)\\n\\nfor w in cloud.canvas:\\n    ax.text(w[\"x\"], w[\"y\"], w[\"word\"], fontsize=w[\"font_size\"]//3)\\n\\nax.axis([0, 1920, 0, 1080])\\n\\n'"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = []\n",
    "for kw, d in kw_max_dim.items():\n",
    "    words.append(Word(kw, {\"width\": d[0], \"height\": d[1]}, kw_fs[kw], kw_cluster[kw]))\n",
    "\n",
    "cloud = Cloud(words=words)\n",
    "\n",
    "cloud.create_cloud()\n",
    "\n",
    "cloud.draw_cloud_to_svg()\n",
    "#cloud.compress()\n",
    "\n",
    "#print(cloud.canvas)\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "fig.subplots_adjust(top=0.85)\n",
    "\n",
    "for w in cloud.canvas:\n",
    "    ax.text(w[\"x\"], w[\"y\"], w[\"word\"], fontsize=w[\"font_size\"]//3)\n",
    "\n",
    "ax.axis([0, 1920, 0, 1080])\n",
    "\n",
    "'''\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vertex:\n",
    "    def __init__(self, node):\n",
    "        self.id = node # we have a dict {id : { word, weight } }\n",
    "        self.adjacent = {}\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.id) + ' adjacent: ' + str([x.id for x in self.adjacent])\n",
    "\n",
    "    def add_neighbor(self, neighbor, weight=0):\n",
    "        self.adjacent[neighbor] = weight\n",
    "\n",
    "    def get_connections(self):\n",
    "        return self.adjacent.keys()  \n",
    "\n",
    "    def get_id(self):\n",
    "        return self.id\n",
    "\n",
    "    def get_weight(self, neighbor):\n",
    "        return self.adjacent[neighbor]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self):\n",
    "        self.vert_dict = {}\n",
    "        self.num_vertices = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.vert_dict.values())\n",
    "\n",
    "    def add_vertex(self, node):\n",
    "        self.num_vertices = self.num_vertices + 1\n",
    "        new_vertex = Vertex(node)\n",
    "        self.vert_dict[node] = new_vertex\n",
    "        return new_vertex\n",
    "\n",
    "    def get_vertex(self, n):\n",
    "        if n in self.vert_dict:\n",
    "            return self.vert_dict[n]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def add_edge(self, frm, to, cost = 0):\n",
    "        if frm not in self.vert_dict:\n",
    "            self.add_vertex(frm)\n",
    "        if to not in self.vert_dict:\n",
    "            self.add_vertex(to)\n",
    "\n",
    "        self.vert_dict[frm].add_neighbor(self.vert_dict[to], cost)\n",
    "        self.vert_dict[to].add_neighbor(self.vert_dict[frm], cost)\n",
    "\n",
    "    def get_vertices(self):\n",
    "        return self.vert_dict.keys()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Star Forest Clustering and putting together\n",
    "'''\n",
    "\n",
    "def StarForestAlgo(g):\n",
    "    '''\n",
    "    g = similarity graph\n",
    "    '''\n",
    "    stars = []\n",
    "    while True:\n",
    "        usedVertices = []\n",
    "        bestCenter = findBestCenter(g, usedVertices)\n",
    "\n",
    "        if bestCenter is None:\n",
    "            break; \n",
    "        \n",
    "        star, usedVertices = createGraphStar(g, bestCenter, usedVertices) # graph, vertice, [vertices]\n",
    "        print(usedVertices)\n",
    "        stars.append(star)\n",
    "        \n",
    "        \n",
    "    return stars\n",
    "\n",
    "\n",
    "def findBestCenter(g, usedVertices): # graph, [vertices]\n",
    "    best_sum = 0\n",
    "    best_center = None\n",
    "    for v in g.get_vertices():\n",
    "        if v not in usedVertices:\n",
    "            sum = getSumOfConnectedEdges(g, v, usedVertices)\n",
    "            if sum > best_sum:\n",
    "                best_center = v\n",
    "    return best_center\n",
    "\n",
    "\n",
    "def getSumOfConnectedEdges(g, v, usedVertices):\n",
    "    sum = 0\n",
    "    connections = g.get_vertex(v).get_connections()\n",
    "    for c in connections:\n",
    "        if c not in usedVertices:\n",
    "            sum += g.get_vertex(v).get_weight(c)\n",
    "    return sum\n",
    "    \n",
    "\n",
    "def createGraphStar(g, bestCenter, usedVertices):\n",
    "    star = Graph()\n",
    "    for v in g.get_vertex(bestCenter).get_connections():\n",
    "        if v not in usedVertices and g.get_vertex(bestCenter) != v:\n",
    "            star.add_edge(bestCenter, v, g.get_vertex(bestCenter).get_weight(v))\n",
    "            print(v)\n",
    "            usedVertices.append(v)\n",
    "    return star, usedVertices\n",
    "\n",
    "\n",
    "\n",
    "g = Graph()\n",
    "\n",
    "g.add_vertex('a')\n",
    "g.add_vertex('b')\n",
    "g.add_vertex('c')\n",
    "g.add_vertex('d')\n",
    "g.add_vertex('e')\n",
    "g.add_vertex('f')\n",
    "\n",
    "g.add_edge('a', 'b', 7)  \n",
    "g.add_edge('a', 'c', 9)\n",
    "g.add_edge('a', 'f', 14)\n",
    "g.add_edge('b', 'c', 10)\n",
    "g.add_edge('b', 'd', 15)\n",
    "g.add_edge('c', 'd', 11)\n",
    "g.add_edge('c', 'f', 2)\n",
    "g.add_edge('d', 'e', 6)\n",
    "g.add_edge('e', 'f', 9)\n",
    "\n",
    "#StarForestAlgo(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aspect ration of words : font_size (length) font_size*0.7(width)\n",
    "# Aspect ration of SVG file is 16:9\n",
    "\n",
    "# How to draw V1 \n",
    "# Create a polygon with the number of vertices = number of clusters \n",
    "# here cluster size = 3 so a triangle (not ever going to exceed 5)\n",
    "# 3 rectangles to fit within the first rectangle \n",
    "\n",
    "# in a 16:9\n",
    "\n",
    "# Cluster one in rect 1 (y = 16, 9/4) (w: 8, l: 9/2)\n",
    "# cluster Two in rect 2 (y = 16, 9/4*3) (w: 8, l: 9/2)\n",
    "# Cluster three in rect 3 (y = 8, 9/4) Biggest cluster ? (w: 8, l: 9/2)\n",
    "\n",
    "# Where to put the words \n",
    "# Start with the highest frequence with the biggest font : assign max font size before starting to draw\n",
    "# If the next one is smaller in frequence, font size drops by \n",
    "# font size 35 to 18\n",
    "# random choice where the word fits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    def seam_carving(self):\n",
    "        board = self.make_board()\n",
    "        sparse = 0\n",
    "        while sparse < 500:\n",
    "            print(sparse)\n",
    "            sparse += 1\n",
    "            self.find_and_remove_path(board)\n",
    "            board = self.make_board()\n",
    "            \n",
    "    def find_and_remove_path(self, board):\n",
    "        v_path = []\n",
    "        h_path = []\n",
    "        sparse = True\n",
    "        for y in range(self.canvas_size[\"y\"]):\n",
    "            pt = {}\n",
    "            pt[\"y\"] = y\n",
    "            pt[\"x\"] = np.argmin(board[y])\n",
    "            v_path.append(pt) # first step \n",
    "            \n",
    "        for x in range(self.canvas_size[\"x\"]):\n",
    "            pt = {}\n",
    "            pt[\"x\"] = x\n",
    "            pt[\"y\"] = np.argmin(board[:,x])\n",
    "            h_path.append(pt) # first step \n",
    "        \n",
    "        for p in v_path + h_path:\n",
    "            for w in self.canvas:\n",
    "                if w[\"x\"] > p[\"x\"]:\n",
    "                    w[\"x\"]-= 1\n",
    "                if w[\"y\"] > p[\"y\"]:\n",
    "                    w[\"y\"] -= 1\n",
    "                    \n",
    "        board = self.make_board()\n",
    "        return sparse\n",
    "\n",
    "    \n",
    "    def make_board(self):\n",
    "        cv = self.canvas\n",
    "        # map canvas to a 1920 1080 matrix \n",
    "        board = np.zeros(shape=(1080, 1920)) #lines, columns\n",
    "        for w in cv:\n",
    "            for i in range(int(w[\"y\"]) - int(w[\"height\"]), int(w[\"y\"])+1):\n",
    "                board[i][int(w[\"x\"]) : int(w[\"x\"]) + int(w[\"width\"]) +1 ] = 1\n",
    "        return board\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
